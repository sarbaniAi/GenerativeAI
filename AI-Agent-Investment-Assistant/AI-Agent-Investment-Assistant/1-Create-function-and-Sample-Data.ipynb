{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a37c090-0547-45d8-9366-9eccb4416489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## This notebook will \n",
    "\n",
    "- Create the required Agent tools - functions\n",
    "- Create the sample data & upload in Delta Tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71a72715-593f-44d1-840a-57bba05a0e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Create UC-Functions to access the yahoo finance API\n",
    "\n",
    "Get access to :\n",
    "https://www.financeapi.net/\n",
    "\n",
    "Create your own API-KEY ( free key will have limitations, please check the dashboard, limk below)\n",
    "\n",
    "Access to Yahoofinace dashboard : \n",
    " https://www.financeapi.net/dashboard\n",
    "\n",
    " \n",
    "\n",
    "Yahoofinance alternative \n",
    "\n",
    "https://site.financialmodelingprep.com/developer/docs#balance-sheet-statements-financial-statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa263aed-fb54-40a6-97a2-c7d74f9f444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I have used one specfic researcher \"Argus Research\" to limit the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba707da1-0ea1-4aa7-aa30-8f6c601322fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.finance_insight_api;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "253fd0f3-14c3-4c18-9ab6-fb6c71e6c22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the existing function if it exists to avoid conflicts\n",
    "spark.sql('DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.finance_insight_api;')\n",
    "\n",
    "# Create or replace the Unity Catalog function for financial insights\n",
    "spark.sql('''\n",
    "CREATE OR REPLACE FUNCTION sarbanimaiti_catalog.agent_demo.finance_insight_api (query STRING)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "COMMENT 'Returns financial insights for a given ticker symbol.'\n",
    "AS\n",
    "$$\n",
    "try:\n",
    "    # Import requests module to make HTTP requests\n",
    "    import requests\n",
    "    # Define the API endpoint for financial insights\n",
    "    url = \"https://yfapi.net/ws/insights/v1/finance/insights\"\n",
    "\n",
    "    # Set the query parameter with the symbol provided to the function\n",
    "    params = {\"symbol\": query}\n",
    "\n",
    "    # Include your API key in the request headers for authentication\n",
    "    headers = {\n",
    "        'x-api-key': \"<your own api-key>\"\n",
    "    }\n",
    "\n",
    "    # Make a GET request to the API\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "\n",
    "    # Initialize an empty list to hold summaries\n",
    "    summaries = []\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    # Control variable to ensure only one summary is added\n",
    "    cntrol = 1\n",
    "\n",
    "    # Iterate through the reports in the response\n",
    "    for report in data['finance']['result']['reports']:\n",
    "        # Check if the report is from Argus Research and control is 1\n",
    "        if report['provider'] == \"Argus Research\" and cntrol ==1:\n",
    "            # Append the summary to the summaries list\n",
    "            summaries.append(report['summary'])\n",
    "            # Update control to prevent adding more summaries\n",
    "            cntrol = cntrol + 1\n",
    "\n",
    "    # Return the list of summaries\n",
    "    return summaries\n",
    "except Exception as e:\n",
    "    # Return an error message if an exception occurs\n",
    "    return \"Error calling YouTube Search API: {{e}}\".format(e=str(e))\n",
    "$$;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad442ff8-df32-4a00-8eea-5e1671e28820",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the finance_insight_api function with 'AAPL' as the parameter and collect the result\n",
    "result = spark.sql(\"SELECT sarbanimaiti_catalog.agent_demo.finance_insight_api('AAPL')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0db8fca-97ce-4870-83d8-42ff5f64df1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d19ba5e-0da3-45a0-a1ae-ebd85ce3ebc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Drop the existing function to avoid conflicts\n",
    "# spark.sql('DROP FUNCTION IF EXISTS sarbanimaiti_catalog.finance_stock_quote.finance_api;')\n",
    "\n",
    "# Define a new function in the Unity Catalog\n",
    "spark.sql('''\n",
    "CREATE OR REPLACE FUNCTION sarbanimaiti_catalog.agent_demo.finance_stock_quote (query STRING)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "COMMENT 'Returns financial summary of ticker.'\n",
    "AS\n",
    "$$\n",
    "try:\n",
    "    # Import requests to enable HTTP calls\n",
    "    import requests\n",
    "    # API endpoint for fetching finance quotes\n",
    "    url = \"https://yfapi.net/v6/finance/quote\"\n",
    "    # Parameters for the API call, specifying the stock symbols\n",
    "    params = {\"symbols\": query}\n",
    "    # Headers for the API call, including the API key for authentication\n",
    "    headers = {\n",
    "        'x-api-key': \"<your own api-key>\"\n",
    "    }\n",
    "    # Execute the GET request with specified URL, headers, and parameters\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    # Return the JSON response from the API\n",
    "    return response.json()\n",
    "except Exception as e:\n",
    "    # Return an error message if an exception occurs\n",
    "    return \"Error calling YouTube Search API: {{e}}\".format(e=str(e))\n",
    "$$;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e67c6302-5d84-45e9-a1ea-a3214b859d00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test the SQL function to get the real time price , financial summary for the ticker 'AAPL' and collect the result\n",
    "result = spark.sql(\"SELECT sarbanimaiti_catalog.agent_demo.finance_stock_quote('AAPL')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e07b3af6-2f3b-49c0-86f8-1caa723e4711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf58cee1-4c1f-4d56-a52b-51922a2851e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the stock historical price tables\n",
    "\n",
    "##### Upload the stock historical files from \"sample_stock_hist_files\" folder to your Unity catalog Volume. \n",
    "In real case these files can be sourced in various ways.\n",
    "\n",
    "##### Then  run the below code to :\n",
    "- Merge all the files in one spark data frame\n",
    "- Then upload the themerged file in spark delta table which will be used in UC function (Agent Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8117310a-1ed7-4741-809d-5918800170b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name, col, regexp_extract\n",
    "\n",
    "# Function to rename columns to remove spaces and special characters\n",
    "def rename_columns(df):\n",
    "    return df.select([col(c).alias(c.replace(\" \", \"_\").replace(\"Adj Close\", \"Adj_Close\")) for c in df.columns])\n",
    "\n",
    "# Load CSV files and add a column with the file name, then rename columns\n",
    "tsla_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/TSLA_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 4))\n",
    "    \n",
    ")\n",
    "\n",
    "aapl_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/AAPL_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 4))\n",
    ")\n",
    "\n",
    "googl_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/GOOGL_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 4))\n",
    ")\n",
    "\n",
    "jnj_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/JNJ_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 3))\n",
    ")\n",
    "\n",
    "jpm_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/JPM_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 3))\n",
    ")\n",
    "\n",
    "amzn_df = rename_columns(\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"/Volumes/sarbanimaiti_catalog/agent_demo/stocks_historical_price/stock_hist_price/AMZN_prices.csv\")\n",
    "    .withColumn(\"stock_name\", regexp_extract(input_file_name(), r'([^/]+)(?=\\.)', 1).substr(0, 4))\n",
    ")\n",
    "\n",
    "\n",
    "# Union all dataframes\n",
    "merged_df = tsla_df.union(aapl_df).union(googl_df).union(jnj_df).union(jpm_df).union(amzn_df)\n",
    "\n",
    "# Write to a Delta table\n",
    "merged_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"sarbanimaiti_catalog.agent_demo.merged_stock_prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f95c672-e653-40b5-86c6-68f2f7c50ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- verify the table \n",
    "SELECT DISTINCT stock_name FROM sarbanimaiti_catalog.agent_demo.merged_stock_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b830bb-4401-4215-be8f-7754594466e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Agent Tool : Extract stock closing price from history table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f2d7a3a-7ea4-4f6d-b9cb-addf7e0ad45a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Drop the existing function to avoid conflicts\n",
    "DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.get_historical_closing_price;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca41db02-98bf-4fc8-aa27-6ebd33ee9ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Drop the existing function to avoid conflicts\n",
    "--spark.sql('DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.get_historical_closing_price;')\n",
    "\n",
    "-- This function takes stock ticker and duration in terms of year as input, refer the corresponding stock historical price table and fetch the historical closing price & volume of the stock for that duration. \n",
    "-- Duration in year  eg : '3'\n",
    "CREATE OR REPLACE FUNCTION sarbanimaiti_catalog.agent_demo.get_hist_closing_price (\n",
    "  stock_ticker STRING COMMENT 'Stock ticker will be passed in the query',\n",
    "  yr_duration  BIGINT COMMENT 'Duration for which stock volume and closing price will be extracted'\n",
    "  \n",
    ")\n",
    "returns table(Date DATE , Close FLOAT, Volume INT)\n",
    "return\n",
    "(\n",
    "WITH FilteredStocks AS (\n",
    "  SELECT\n",
    "    Date,\n",
    "    Close,\n",
    "    Volume,\n",
    "    stock_name\n",
    "  FROM\n",
    "    sarbanimaiti_catalog.agent_demo.merged_stock_prices\n",
    "  WHERE\n",
    "    stock_name = stock_ticker\n",
    "    AND datediff(CURRENT_DATE(), Date) <= 400 * yr_duration\n",
    ")\n",
    "SELECT\n",
    "  Date,\n",
    "  Close,\n",
    "  Volume\n",
    "FROM\n",
    "  FilteredStocks\n",
    "ORDER BY\n",
    "  Date ASC\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dea4d5a9-283f-4553-a52b-eece98578798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Test the tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b17bcba9-3345-48bd-b535-14d62bf2bf46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "SELECT * FROM sarbanimaiti_catalog.agent_demo.get_hist_closing_price('JPM', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5a3fde7-c108-4a4d-b60a-c02e2c0e05f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create table to load customer investment preference data\n",
    "\n",
    "Stesp:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93602364-277f-4c2e-9ad0-cf6dcb359e8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f06dbe6-7335-4137-9e34-8f6bb139e9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for generating synthetic data\n",
    "fake = Faker()\n",
    "\n",
    "# Define ranges and options for generating data\n",
    "income_ranges = [\"low\", \"medium\", \"high\"]\n",
    "risk_tolerances = [\"low\", \"medium\", \"high\"]\n",
    "investment_horizons = [\"short-term\", \"medium-term\", \"long-term\"]\n",
    "investment_goals = [\"retirement\", \"wealth accumulation\", \"education\", \"savings\"]\n",
    "industries = [\"tech\", \"healthcare\", \"energy\", \"finance\", \"consumer goods\"]\n",
    "stock_types = [\"growth\", \"dividend\", \"blue-chip\", \"value\", \"penny\"]\n",
    "trading_frequencies = [\"daily\", \"weekly\", \"monthly\"]\n",
    "holding_periods = [\"days\", \"weeks\", \"months\", \"years\"]\n",
    "special_requirements_options = [\"ESG-focused investments\", \"no tobacco stocks\", \"\", \"\", \"\"]\n",
    "\n",
    "# Generate synthetic data\n",
    "data = []\n",
    "num_records = 100  # Number of records to generate\n",
    "\n",
    "for _ in range(num_records):\n",
    "    customer_id = fake.random_int(min=1000, max=9999)\n",
    "    age = fake.random_int(min=18, max=75)\n",
    "    gender = fake.random_element(elements=(\"Male\", \"Female\"))\n",
    "    income_range = fake.random_element(elements=income_ranges)\n",
    "    risk_tolerance = fake.random_element(elements=risk_tolerances)\n",
    "    investment_horizon = fake.random_element(elements=investment_horizons)\n",
    "    investment_goal = fake.random_element(elements=investment_goals)\n",
    "    preferred_industries = random.sample(industries, k=random.randint(1, 3))\n",
    "    preferred_stock_type = fake.random_element(elements=stock_types)\n",
    "    average_investment_amount = round(random.uniform(1000, 100000), 2)\n",
    "    trading_frequency = fake.random_element(elements=trading_frequencies)\n",
    "    holding_period = fake.random_element(elements=holding_periods)\n",
    "    historical_performance = json.dumps({\n",
    "        \"avg_return\": round(random.uniform(-10, 20), 2),\n",
    "        \"volatility\": round(random.uniform(0.5, 3.0), 2)\n",
    "    })\n",
    "    special_requirements = fake.random_element(elements=special_requirements_options)\n",
    "    \n",
    "    # Add record to data list\n",
    "    data.append([\n",
    "        customer_id, age, gender, income_range, risk_tolerance, investment_horizon, \n",
    "        investment_goal, preferred_industries, preferred_stock_type, \n",
    "        average_investment_amount, trading_frequency, holding_period, \n",
    "        historical_performance, special_requirements\n",
    "    ])\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\n",
    "    \"customer_id\", \"age\", \"gender\", \"income_range\", \"risk_tolerance\", \"investment_horizon\",\n",
    "    \"investment_goals\", \"preferred_industries\", \"preferred_stock_types\", \n",
    "    \"average_investment_amount\", \"trading_frequency\", \"holding_period\", \n",
    "    \"historical_performance\", \"special_requirements\"\n",
    "]\n",
    "df_synthetic = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save to CSV if needed\n",
    "#df_synthetic.to_csv(\"customer_stock_preferences_synthetic.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic data generated and saved to 'customer_stock_preferences_synthetic.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f10158e8-6149-4f62-8206-4f9b1e7516aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Upload Customer Stock Preferences data to spark delta table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d75004e-f14f-4c9b-9369-a002073d7f7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df_synthetic)\n",
    "df_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"sarbanimaiti_catalog.agent_demo.customer_investment_preferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d753ae76-2ee1-4740-a752-4df4708543c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Agent Tool : Extract Customer investment preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b077fe91-b709-4ada-a52d-16257ae54331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Again check that it exists\n",
    "DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.customer_investment_preferences;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e52eb3-26ca-4e85-8678-5a7094666e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Again check that it exists\n",
    "DROP FUNCTION IF EXISTS sarbanimaiti_catalog.agent_demo.cust_investment_pref;\n",
    "\n",
    "-- This function takes stock ticker and duration in terms of year as input, refer the corresponding stock historical price table and fetch the historical closing price & volume of the stock for that duration. \n",
    "-- Duration in year  eg : '3'\n",
    "CREATE OR REPLACE FUNCTION sarbanimaiti_catalog.agent_demo.cust_investment_pref (\n",
    "  customerID BIGINT COMMENT 'Customer ID'\n",
    "  \n",
    ")\n",
    "returns table(\n",
    "  customer_id BIGINT, \n",
    "  age BIGINT,\n",
    "  gender STRING, \n",
    "  income_range STRING, \n",
    "  risk_tolerance STRING, \n",
    "  investment_horizon STRING, \n",
    "  investment_goals STRING, \n",
    "  preferred_industries STRING, \n",
    "  preferred_stock_types STRING, \n",
    "  average_investment_amount DOUBLE, \n",
    "  trading_frequency BIGINT, \n",
    "  holding_period BIGINT, \n",
    "  historical_performance DOUBLE, \n",
    "  special_requirements STRING)\n",
    "return\n",
    "(\n",
    "WITH CustomerPreference  AS (\n",
    "  SELECT\n",
    "    customer_id, \n",
    "    age,\n",
    "    gender, \n",
    "    income_range, \n",
    "    risk_tolerance, \n",
    "    investment_horizon, \n",
    "    investment_goals, \n",
    "    preferred_industries, \n",
    "    preferred_stock_types, \n",
    "    average_investment_amount, \n",
    "    trading_frequency, \n",
    "    holding_period, \n",
    "    historical_performance, \n",
    "    special_requirements\n",
    "  FROM\n",
    "    sarbanimaiti_catalog.agent_demo.customer_investment_preferences\n",
    "  WHERE\n",
    "    customer_id = customerID )\n",
    "  select * from CustomerPreference \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a5a15f1-1f19-4050-84e9-d573c12ea589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--test function\n",
    "select * from sarbanimaiti_catalog.agent_demo.cust_investment_pref(3584)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62fab4a3-9ea5-42f5-950c-12dd1598dd02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 117686861093206,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "1-Create-function-and-Sample-Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
